{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzHWoa377tS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad36977d-ca7c-45b6-d0f4-f027f941e3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji==1.6.3 in /usr/local/lib/python3.10/dist-packages (1.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade emoji==1.6.3\n",
        "\n",
        "import numpy as np\n",
        "from emo_utils import *\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from test_utils import *\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the zip file path\n",
        "zip_file = 'data/glove.6B.50d.txt.zip'\n",
        "\n",
        "# Extract the zip file into the same directory\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')  # Extracts all files to the current directory\n"
      ],
      "metadata": {
        "id": "6s2VVS_Ed-Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
        "X_test, Y_test = read_csv('data/tesss.csv')"
      ],
      "metadata": {
        "id": "vGbTo6CZ8HjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X_train, key=len).split())"
      ],
      "metadata": {
        "id": "Cv9XOoSn8MLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
      ],
      "metadata": {
        "id": "1nJmg2ry8P_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2048438b-6c6c-48ab-c139-9a6dfa5ac8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÑ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n",
            "I love you mum ‚ù§Ô∏è\n",
            "Stop saying bullshit üòû\n",
            "congratulations on your acceptance üòÑ\n",
            "The assignment is too long  üòû\n",
            "I want to go play ‚öæ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
      ],
      "metadata": {
        "id": "R3QKMGSK8Sv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 50\n",
        "print(f\"Sentence '{X_train[50]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
        "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
      ],
      "metadata": {
        "id": "l1r8R5oT8W0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4353f868-83b1-4737-c231-7f9efb3152d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
            "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "TeJhYIP28YfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"cucumber\"\n",
        "idx = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ],
      "metadata": {
        "id": "ECoAL39P8aSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4067b2-3b29-4ebd-f2c2-01e3ba6dcb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the index of cucumber in the vocabulary is 113317\n",
            "the 289846th word in the vocabulary is potatos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def sentence_to_avg(sentence, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
        "    and averages its value into a single vector encoding the meaning of the sentence.\n",
        "\n",
        "    Arguments:\n",
        "    sentence -- string, one training example from X\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "\n",
        "    Returns:\n",
        "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
        "    \"\"\"\n",
        "    # Get a valid word contained in the word_to_vec_map.\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Step 1: Split sentence into list of lower case words (‚âà 1 line)\n",
        "    words = sentence.lower().split()\n",
        "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
        "    avg_word = np.zeros(word_to_vec_map[any_word].shape)\n",
        "\n",
        "    # Initialize count to 0\n",
        "    count = 0\n",
        "\n",
        "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
        "    # problem was inside comments inside the loop does it exist or not\n",
        "    avg = 0\n",
        "    for word in words:\n",
        "      if word in word_to_vec_map:\n",
        "        avg_word += word_to_vec_map[word]\n",
        "        count+=1\n",
        "    if count > 0:\n",
        "        avg = avg_word / count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return avg"
      ],
      "metadata": {
        "id": "1zejRBtn8cEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN UNIT TEST\n",
        "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
        "print(\"avg = \\n\", avg)\n",
        "\n",
        "def sentence_to_avg_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    avg = target(\"a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert tuple(avg.shape) == tuple(word_to_vec_map['a'].shape),  \"Check the shape of your avg array\"\n",
        "    assert np.allclose(avg, [1.25, 2.5]),  \"Check that you are finding the 4 words\"\n",
        "    avg = target(\"love a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [1.25, 2.5]), \"Divide by count, not len(words)\"\n",
        "    avg = target(\"love\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0, 0]), \"Average of no words must give an array of zeros\"\n",
        "    avg = target(\"c_se foo a a_nw c_w a_s deeplearning c_nw\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0.1666667, 2.0]), \"Debug the last example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentence_to_avg_test(sentence_to_avg)\n",
        "\n",
        "# END UNIT TEST"
      ],
      "metadata": {
        "id": "oHNIbzPl8i64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e92be2f-eae4-449c-e827-8da08908075e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg = \n",
            " [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
            " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
            "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
            "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
            "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
            "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
            " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
            " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
            "  0.1445417   0.09808667]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 200):\n",
        "    \"\"\"\n",
        "    Model to train word vector representations in numpy.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
        "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
        "    num_iterations -- number of iterations\n",
        "\n",
        "    Returns:\n",
        "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
        "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
        "    b -- bias of the softmax layer, of shape (n_y,)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get a valid word contained in the word_to_vec_map\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "\n",
        "    # Initialize cost. It is needed during grading\n",
        "    cost = 0\n",
        "\n",
        "    # Define number of training examples\n",
        "    m = Y.shape[0]                             # number of training examples\n",
        "    n_y = len(np.unique(Y))                    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors\n",
        "\n",
        "    # Initialize parameters using Xavier initialization\n",
        "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
        "    b = np.zeros((n_y,))\n",
        "\n",
        "    # Convert Y to Y_onehot with n_y classes\n",
        "    Y_oh = convert_to_one_hot(Y, C = n_y)\n",
        "\n",
        "    # Optimization loop\n",
        "    for t in range(num_iterations): # Loop over the number of iterations\n",
        "        for i in range(m):          # Loop over the training examples\n",
        "\n",
        "            ### START CODE HERE ### (‚âà 4 lines of code)\n",
        "            # Average the word vectors of the words from the i'th training example\n",
        "\n",
        "            avg = sentence_to_avg(X[i],word_to_vec_map)\n",
        "            z = np.dot(W,avg)+b\n",
        "\n",
        "\n",
        "            # Forward propagate the avg through the softmax layer\n",
        "            a = softmax(z)\n",
        "\n",
        "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
        "            cost = np.sum(Y_oh[i] * np.log(a))\n",
        "\n",
        "            ### END CODE HERE ###\n",
        "\n",
        "            # Compute gradients\n",
        "            dz = a - Y_oh[i]\n",
        "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
        "            db = dz\n",
        "\n",
        "            # Update parameters with Stochastic Gradient Descent\n",
        "            W = W - learning_rate * dW\n",
        "            b = b - learning_rate * db\n",
        "\n",
        "        if t % 10 == 0:\n",
        "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
        "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
        "\n",
        "    return pred, W, b"
      ],
      "metadata": {
        "id": "LuiN9QHM8pz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIT TEST\n",
        "def model_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Training set. Sentences composed of a_* words will be of class 0 and sentences composed of c_* words will be of class 1\n",
        "    X = np.asarray(['a a_s synonym_of_a a_n c_sw', 'a a_s a_n c_sw', 'a_s  a a_n', 'synonym_of_a a a_s a_n c_sw', \" a_s a_n\",\n",
        "                    \" a a_s a_n c \", \" a_n  a c c c_e\",\n",
        "                   'c c_nw c_n c c_ne', 'c_e c c_se c_s', 'c_nw c a_s c_e c_e', 'c_e a_nw c_sw', 'c_sw c c_ne c_ne'])\n",
        "\n",
        "    Y = np.asarray([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "    np.random.seed(10)\n",
        "    pred, W, b = model(X, Y, word_to_vec_map, 0.0025, 110)\n",
        "\n",
        "    assert W.shape == (2, 2), \"W must be of shape 2 x 2\"\n",
        "    assert np.allclose(pred.transpose(), Y), \"Model must give a perfect accuracy\"\n",
        "    assert np.allclose(b[0], -1 * b[1]), \"b should be symmetric in this example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "model_test(model)"
      ],
      "metadata": {
        "id": "LW1GYfiX8u4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a0c7b9-fc24-4f84-99a2-bfe890914c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = -0.05105772513207823\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 10 --- cost = -0.03893716809550303\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 20 --- cost = -0.03078199487865477\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 30 --- cost = -0.0250625254818359\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 40 --- cost = -0.020906296817970453\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 50 --- cost = -0.017791876552201644\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 60 --- cost = -0.015394747683241103\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 70 --- cost = -0.01350575460904451\n",
            "Accuracy: 1.0\n",
            "Epoch: 80 --- cost = -0.01198593465621373\n",
            "Accuracy: 1.0\n",
            "Epoch: 90 --- cost = -0.01074046826626526\n",
            "Accuracy: 1.0\n",
            "Epoch: 100 --- cost = -0.00970311068897676\n",
            "Accuracy: 1.0\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
        "print(X_train[0])\n",
        "print(type(X_train))\n",
        "Y = np.asarray([5, 0, 0, 5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
        "print(Y.shape)\n",
        "\n",
        "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
        " 'Lets go party and have drinks','Congrats on the new job','Congratulations',\n",
        " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
        " 'You totally deserve this prize', 'Let us go play football',\n",
        " 'Are you down for football this afternoon', 'Work hard play harder',\n",
        " 'It is surprising how people can be dumb sometimes',\n",
        " 'I am very disappointed','It is the best day in my life',\n",
        " 'I think I will end up alone','My life is so boring','Good job',\n",
        " 'Great so awesome'])\n",
        "\n",
        "print(X.shape)\n",
        "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
        "print(type(X_train))"
      ],
      "metadata": {
        "id": "llpcpp138yRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fbe79d-ccc1-4b9f-e786-105258e62757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132,)\n",
            "(132,)\n",
            "(132, 5)\n",
            "never talk to me again\n",
            "<class 'numpy.ndarray'>\n",
            "(20,)\n",
            "(20,)\n",
            "(132, 5)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "tf_bWuCm8zwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cf16c2-c5c3-4141-a7a0-a4d9c179dcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = -1.9520498812810076\n",
            "Accuracy: 0.3484848484848485\n",
            "Epoch: 10 --- cost = -1.0040987758894053\n",
            "Accuracy: 0.7272727272727273\n",
            "Epoch: 20 --- cost = -0.5388772571119417\n",
            "Accuracy: 0.803030303030303\n",
            "Epoch: 30 --- cost = -0.3331218997365079\n",
            "Accuracy: 0.803030303030303\n",
            "Epoch: 40 --- cost = -0.23144766289423163\n",
            "Accuracy: 0.8257575757575758\n",
            "Epoch: 50 --- cost = -0.1747265584802322\n",
            "Accuracy: 0.8560606060606061\n",
            "Epoch: 60 --- cost = -0.1398575258401195\n",
            "Accuracy: 0.8787878787878788\n",
            "Epoch: 70 --- cost = -0.1167706122397682\n",
            "Accuracy: 0.8939393939393939\n",
            "Epoch: 80 --- cost = -0.10058743375666801\n",
            "Accuracy: 0.9090909090909091\n",
            "Epoch: 90 --- cost = -0.08872634092095644\n",
            "Accuracy: 0.9242424242424242\n",
            "Epoch: 100 --- cost = -0.07971818726014807\n",
            "Accuracy: 0.9318181818181818\n",
            "Epoch: 110 --- cost = -0.07267535951826085\n",
            "Accuracy: 0.9318181818181818\n",
            "Epoch: 120 --- cost = -0.0670345060004128\n",
            "Accuracy: 0.9318181818181818\n",
            "Epoch: 130 --- cost = -0.06242326850488144\n",
            "Accuracy: 0.9318181818181818\n",
            "Epoch: 140 --- cost = -0.05858708329632528\n",
            "Accuracy: 0.9393939393939394\n",
            "Epoch: 150 --- cost = -0.055346878990539604\n",
            "Accuracy: 0.9393939393939394\n",
            "Epoch: 160 --- cost = -0.052573552521839984\n",
            "Accuracy: 0.9393939393939394\n",
            "Epoch: 170 --- cost = -0.05017200064054583\n",
            "Accuracy: 0.9393939393939394\n",
            "Epoch: 180 --- cost = -0.04807081857515234\n",
            "Accuracy: 0.946969696969697\n",
            "Epoch: 190 --- cost = -0.04621547640746089\n",
            "Accuracy: 0.9545454545454546\n",
            "[[3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [4.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [1.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [2.]\n",
            " [2.]\n",
            " [1.]\n",
            " [4.]\n",
            " [3.]\n",
            " [3.]\n",
            " [4.]\n",
            " [0.]\n",
            " [3.]\n",
            " [4.]\n",
            " [2.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [4.]\n",
            " [2.]\n",
            " [2.]\n",
            " [0.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]\n",
            " [4.]\n",
            " [3.]\n",
            " [0.]\n",
            " [3.]\n",
            " [3.]\n",
            " [3.]\n",
            " [4.]\n",
            " [2.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [3.]\n",
            " [4.]\n",
            " [4.]\n",
            " [2.]\n",
            " [2.]\n",
            " [1.]\n",
            " [2.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [0.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [2.]\n",
            " [1.]\n",
            " [2.]\n",
            " [2.]\n",
            " [4.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [4.]\n",
            " [0.]\n",
            " [0.]\n",
            " [3.]\n",
            " [3.]\n",
            " [3.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [2.]\n",
            " [4.]\n",
            " [1.]\n",
            " [1.]\n",
            " [3.]\n",
            " [3.]\n",
            " [4.]\n",
            " [1.]\n",
            " [2.]\n",
            " [1.]\n",
            " [1.]\n",
            " [3.]\n",
            " [1.]\n",
            " [0.]\n",
            " [4.]\n",
            " [0.]\n",
            " [3.]\n",
            " [3.]\n",
            " [4.]\n",
            " [4.]\n",
            " [1.]\n",
            " [4.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set:\")\n",
        "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
        "print('Test set:')\n",
        "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
      ],
      "metadata": {
        "id": "8q473_7U80Uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a861de-8e15-417e-e18a-d3b5063421e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Accuracy: 0.9545454545454546\n",
            "Test set:\n",
            "Accuracy: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single(sentence, W=W, b=b, word_to_vec_map=word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data containing sentences, numpy array of shape (m, None)\n",
        "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
        "\n",
        "    Returns:\n",
        "    pred -- numpy array of shape (m, 1) with your predictions\n",
        "    \"\"\"\n",
        "\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]\n",
        "\n",
        "    # Split jth test example (sentence) into list of lower case words\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    # Average words' vectors\n",
        "    avg = np.zeros((n_h,))\n",
        "    count = 0\n",
        "    for w in words:\n",
        "        if w in word_to_vec_map:\n",
        "            avg += word_to_vec_map[w]\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        avg = avg / count\n",
        "\n",
        "    # Forward propagation\n",
        "    Z = np.dot(W, avg) + b\n",
        "    A = softmax(Z)\n",
        "    pred = np.argmax(A)\n",
        "\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "yP3eB_Nk81-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_emoji(int(predict_single(\"I love you\")))"
      ],
      "metadata": {
        "id": "wj9c3ogc85cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "659159ac-0469-4759-e6f6-1a9b80df2d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚ù§Ô∏è'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
        "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
        "\n",
        "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
        "print_predictions(X_my_sentences, pred)"
      ],
      "metadata": {
        "id": "j-sqdVFx87gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43031db9-e665-4681-ede4-5609bec52b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333333333333334\n",
            "\n",
            "i adore you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÑ\n",
            "lets play with a ball ‚öæ\n",
            "food is ready üç¥\n",
            "not feeling happy üòÑ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# START SKIP FOR GRADING\n",
        "print(Y_test.shape)\n",
        "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
        "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "plot_confusion_matrix(Y_test, pred_test)\n",
        "# END SKIP FOR GRADING"
      ],
      "metadata": {
        "id": "2C0Ug2bx8-No",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "d67146ce-3929-48d4-f2fd-aef9e3d20bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56,)\n",
            "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
            "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
            "Actual                                 \n",
            "0            6    0    0    1    0    7\n",
            "1            0    8    0    0    0    8\n",
            "2            2    0   16    0    0   18\n",
            "3            1    1    2   12    0   16\n",
            "4            0    0    1    0    6    7\n",
            "All          9    9   19   13    6   56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "Xd162VpM9CH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, val in enumerate([\"I\", \"like\", \"learning\"]):\n",
        "    print(idx, val)"
      ],
      "metadata": {
        "id": "uH5UPFIg9Fkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c143769c-6e3f-4c52-e469-fc8e7f217b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 I\n",
            "1 like\n",
            "2 learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: sentences_to_indices\n",
        "\n",
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4).\n",
        "\n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), of shape (m, 1)\n",
        "    word_to_index -- a dictionary containing the each word mapped to its index\n",
        "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this.\n",
        "\n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (‚âà 1 line)\n",
        "    X_indices = np.zeros([m, max_len])\n",
        "\n",
        "\n",
        "    for i in range(m):                               # loop over training examples\n",
        "\n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words = X[i].lower().split()\n",
        "\n",
        "        # Initialize j to 0\n",
        "        j=0\n",
        "\n",
        "        # Loop over the words of sentence_words\n",
        "\n",
        "        for w in sentence_words:\n",
        "            # if w exists in the word_to_index dictionary\n",
        "            if w in word_to_index:\n",
        "\n",
        "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "                X_indices[i,j]     = word_to_index[w]\n",
        "                # Increment j to j + 1\n",
        "                j+=1\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X_indices"
      ],
      "metadata": {
        "id": "AHLCb6WJ9Kz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIT TEST\n",
        "def sentences_to_indices_test(target):\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate([\"i\", \"like\", \"learning\", \"deep\", \"machine\", \"love\", \"smile\", '¬¥0.=']):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    max_len = 4\n",
        "    sentences = np.array([\"I like deep learning\", \"deep ¬¥0.= love machine\", \"machine learning smile\"]);\n",
        "    indexes = target(sentences, word_to_index, max_len)\n",
        "    print(indexes)\n",
        "\n",
        "    assert type(indexes) == np.ndarray, \"Wrong type. Use np arrays in the function\"\n",
        "    assert indexes.shape == (sentences.shape[0], max_len), \"Wrong shape of ouput matrix\"\n",
        "    assert np.allclose(indexes, [[0, 1, 3, 2],\n",
        "                                 [3, 7, 5, 4],\n",
        "                                 [4, 2, 6, 0]]), \"Wrong values. Debug with the given examples\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentences_to_indices_test(sentences_to_indices)"
      ],
      "metadata": {
        "id": "Y-Kl-ko09LTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5003279c-9202-40e0-d515-ec98bc393f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 3. 2.]\n",
            " [3. 7. 5. 4.]\n",
            " [4. 2. 6. 0.]]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\\n\", X1_indices)"
      ],
      "metadata": {
        "id": "56_-nT379NTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e3fd0d-1c29-4227-8f21-958536a73633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "X1_indices =\n",
            " [[155345. 225122.      0.      0.      0.]\n",
            " [220930. 286375.  69714.      0.      0.]\n",
            " [151204. 192973. 302254. 151349. 394475.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: pretrained_embedding_layer\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
        "\n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    embedding_layer -- pretrained layer Keras instance\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_size = len(word_to_index) + 1              # adding 1 to fit Keras embedding (requirement)\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    emb_dim = word_to_vec_map[any_word].shape[0]    # define dimensionality of your GloVe word vectors (= 50)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Step 1\n",
        "    # Initialize the embedding matrix as a numpy array of zeros.\n",
        "    # See instructions above to choose the correct shape.\n",
        "    emb_matrix = np.zeros([vocab_size, emb_dim])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Step 2\n",
        "    # Set each row \"idx\" of the embedding matrix to be\n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "\n",
        "    for word, idx in word_to_index.items():\n",
        "      emb_matrix[idx,:] = word_to_vec_map[word]\n",
        "\n",
        "\n",
        "\n",
        "    # Step 3\n",
        "    # Define Keras embedding layer with the correct input and output sizes\n",
        "    # Make it non-trainable.\n",
        "    embedding_layer = tensorflow.keras.layers.Embedding(vocab_size, emb_dim , trainable = False)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Step 4 (already done for you; please do not modify)\n",
        "    # Build the embedding layer, it is required before setting the weights of the embedding layer.\n",
        "     # Do not modify the \"None\".  This line of code is complete as-is.\n",
        "    embedding_layer.build((None,)) # Do not modify the \"None\".  This line of code is complete as-is.\n",
        "\n",
        "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "\n",
        "    return embedding_layer"
      ],
      "metadata": {
        "id": "849MntoO9PBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIT TEST\n",
        "def pretrained_embedding_layer_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    np.random.seed(1)\n",
        "    embedding_layer = target(word_to_vec_map, word_to_index)\n",
        "\n",
        "    assert type(embedding_layer) == Embedding, \"Wrong type\"\n",
        "    assert embedding_layer.input_dim == len(list(word_to_vec_map.keys())) + 1, \"Wrong input shape\"\n",
        "    assert embedding_layer.output_dim == len(word_to_vec_map['a']), \"Wrong output shape\"\n",
        "    assert np.allclose(embedding_layer.get_weights(),\n",
        "                       [[[ 3, 3], [ 3, 3], [ 2, 4], [ 3, 2], [ 3, 4],\n",
        "                       [-2, 1], [-2, 2], [-1, 2], [-1, 1], [-1, 0],\n",
        "                       [-2, 0], [-3, 0], [-3, 1], [-3, 2], [ 0, 0]]]), \"Wrong vaulues\"\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "\n",
        "pretrained_embedding_layer_test(pretrained_embedding_layer)"
      ],
      "metadata": {
        "id": "mpn2fTFl9R-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3255f213-d3d4-4e0b-93fa-da577d13bd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
        "print(\"Input_dim\", embedding_layer.input_dim)\n",
        "print(\"Output_dim\",embedding_layer.output_dim)"
      ],
      "metadata": {
        "id": "-vH8Rtvd9T6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf8112e-df40-4e8e-b11b-cfd3f46d520c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights[0][1][1] = 0.39031\n",
            "Input_dim 400001\n",
            "Output_dim 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: Emojify_V2\n",
        "\n",
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Function creating the Emojify-v2 model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, usually (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Define sentence_indices as the input of the graph.\n",
        "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
        "    sentence_indices =  Input(shape=input_shape, dtype='int32')\n",
        "    # Create the embedding layer pretrained with GloVe Vectors (‚âà1 line)\n",
        "\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "\n",
        "\n",
        "    # Propagate sentence_indices through your embedding layer\n",
        "    embedding = embedding_layer(sentence_indices)\n",
        "    # (See additional hints in the instructions).\n",
        "\n",
        "\n",
        "\n",
        "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
        "    # The returned output should be a batch of sequences, So, set return_sequences = True\n",
        "    # If return_sequences = False, the LSTM returns only tht last output in output sequence\n",
        "    X = LSTM(units = 128, return_sequences= True )(embedding)\n",
        "\n",
        "    # Add dropout with a probability of 0.5\n",
        "\n",
        "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
        "\n",
        "\n",
        "    # The returned output should be a single hidden state, not a batch of sequences.\n",
        "    X = LSTM(units = 128)(X)\n",
        "\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(rate = 0.5)(X)\n",
        "    # Propagate X through a Dense layer with 5 units\n",
        "    X = Dense(units = 5)(X)\n",
        "    # Add a softmax activation\n",
        "    X = Activation('softmax')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = Model(inputs=sentence_indices, outputs=X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "MkKDlzY69Vb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIT TEST\n",
        "def Emojify_V2_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    maxLen = 4\n",
        "    model = target((maxLen,), word_to_vec_map, word_to_index)\n",
        "\n",
        "    expectedModel = [['InputLayer', [(None, 4)], 0], ['Embedding', (None, 4, 2), 30], ['LSTM', (None, 4, 128), 67072, (None, 4, 2), 'tanh', True], ['Dropout', (None, 4, 128), 0, 0.5], ['LSTM', (None, 128), 131584, (None, 4, 128), 'tanh', False], ['Dropout', (None, 128), 0, 0.5], ['Dense', (None, 5), 645, 'linear'], ['Activation', (None, 5), 0]]\n",
        "    comparator(summary(model), expectedModel)\n",
        "\n",
        "\n",
        "Emojify_V2_test(Emojify_V2)"
      ],
      "metadata": {
        "id": "SEPC4Z319cL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1ee31574-a450-4a8b-a5b1-6f79300139b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'InputLayer' object has no attribute 'output_shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-92cd21827bcb>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mEmojify_V2_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmojify_V2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-92cd21827bcb>\u001b[0m in \u001b[0;36mEmojify_V2_test\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mexpectedModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'InputLayer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Embedding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m67072\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Dropout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m131584\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Dropout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;3...\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcomparator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpectedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/test_utils.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mdescriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'InputLayer' object has no attribute 'output_shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "m3 =  Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "m3.summary()"
      ],
      "metadata": {
        "id": "Si1okfHh9eP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "2267b166-ea04-49c6-972d-8a1d475a28dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              ‚îÇ      \u001b[38;5;34m20,000,050\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             ‚îÇ          \u001b[38;5;34m91,648\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ         \u001b[38;5;34m131,584\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   ‚îÇ             \u001b[38;5;34m645\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,223,927\u001b[0m (77.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,223,927</span> (77.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,877\u001b[0m (874.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,877</span> (874.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,000,050\u001b[0m (76.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> (76.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              ‚îÇ      \u001b[38;5;34m20,000,050\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             ‚îÇ          \u001b[38;5;34m91,648\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ         \u001b[38;5;34m131,584\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   ‚îÇ             \u001b[38;5;34m645\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,223,927\u001b[0m (77.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,223,927</span> (77.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,877\u001b[0m (874.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,877</span> (874.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,000,050\u001b[0m (76.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> (76.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "m3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zSd53mLV9fvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
      ],
      "metadata": {
        "id": "4Kwyu5xU9hTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(X_train_indices, Y_train_oh, epochs = 100, batch_size = 32, shuffle=True)\n",
        "\n",
        "m3.fit(X_train_indices, Y_train_oh, epochs = 100, batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "id": "luQjAdkE9i8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1eb559-eab8-4ba2-ad87-c16062f5dfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.2887 - loss: 1.5892\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3834 - loss: 1.5027\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3493 - loss: 1.4433\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4080 - loss: 1.3696\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5212 - loss: 1.2691\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5670 - loss: 1.1121\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6672 - loss: 0.9988\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5729 - loss: 1.0041\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7335 - loss: 0.8138\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6886 - loss: 0.8070\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7412 - loss: 0.6938\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8166 - loss: 0.5895\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8314 - loss: 0.4762\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8390 - loss: 0.4827\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8149 - loss: 0.5088\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8449 - loss: 0.4366\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7992 - loss: 0.5116\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8498 - loss: 0.4433\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8359 - loss: 0.4368\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8234 - loss: 0.5181\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8733 - loss: 0.3513\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8617 - loss: 0.3562\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8735 - loss: 0.3338\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9298 - loss: 0.2592\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9247 - loss: 0.2356\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9355 - loss: 0.1786\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9290 - loss: 0.1914\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9199 - loss: 0.2423\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7734 - loss: 0.5663\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9063 - loss: 0.2808\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9055 - loss: 0.2477\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9093 - loss: 0.2893\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9321 - loss: 0.1554\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9755 - loss: 0.1431\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9459 - loss: 0.1781\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9531 - loss: 0.1268\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9906 - loss: 0.0740\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9755 - loss: 0.0850\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9824 - loss: 0.0578\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9828 - loss: 0.0531\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0465\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9704 - loss: 0.0815\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0284\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9729 - loss: 0.0528\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9944 - loss: 0.0299\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0112\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9906 - loss: 0.0244\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0197\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9866 - loss: 0.0268\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0176\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0076\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9962 - loss: 0.0103\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0092\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9833 - loss: 0.0413\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9093 - loss: 0.2267\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9786 - loss: 0.0820\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9828 - loss: 0.0442\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9923 - loss: 0.0422\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9694 - loss: 0.0822\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9866 - loss: 0.0279\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9785 - loss: 0.0669\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9923 - loss: 0.0190\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0107\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9918 - loss: 0.0222\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0075\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0080\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0019\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x783b28a04280>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "loss, acc = m3.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ],
      "metadata": {
        "id": "mcuxU6Ff9k1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7b663c-285e-4d8a-ba80-1f234ac5c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8512 - loss: 0.6509 \n",
            "\n",
            "Test accuracy =  0.8392857313156128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows you to see the mislabelled examples\n",
        "C = 5\n",
        "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
        "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
        "pred = model.predict(X_test_indices)\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test_indices\n",
        "    num = np.argmax(pred[i])\n",
        "    if(num != Y_test[i]):\n",
        "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
      ],
      "metadata": {
        "id": "SZpnoGhd9mRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971ad1e1-5d66-4444-ecaf-40659adeaac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n",
            "Expected emoji:üòû prediction: work is hard\tüòÑ\n",
            "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
            "Expected emoji:üòû prediction: work is horrible\tüòÑ\n",
            "Expected emoji:üòÑ prediction: you brighten my day\t‚ù§Ô∏è\n",
            "Expected emoji:üòû prediction: she is a bully\t‚ù§Ô∏è\n",
            "Expected emoji:üòÑ prediction: will you be my valentine\t‚ù§Ô∏è\n",
            "Expected emoji:üòû prediction: go away\t‚öæ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.\n",
        "x_test = np.array([\"I am happy as always\"])\n",
        "\n",
        "#x_test = np.array([\"Today was a tedious day\"])\n",
        "\n",
        "x_test = np.array([\"what a nice picture, you look good\"])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(m3.predict(X_test_indices))))"
      ],
      "metadata": {
        "id": "hJgYn_Yb9oAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645d742d-08b7-4464-d6a9-1e9f181a6c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "what a nice picture, you look good ‚ù§Ô∏è\n"
          ]
        }
      ]
    }
  ]
}